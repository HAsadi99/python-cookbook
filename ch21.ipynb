{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af7e29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 21. Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a109a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 21.1 Using Autograd with PyTorch\n",
    "\n",
    "import torch\n",
    "\n",
    "# create a torch tensor that requires gradients\n",
    "t =torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# Perform a tensor operation simulating \"forward propagation\"\n",
    "tensor_sum = t.sum()\n",
    "\n",
    "# Perform back propagation\n",
    "tensor_sum.backward()\n",
    "\n",
    "# View the gradients\n",
    "t.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "415f5211",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m,\u001b[38;5;241m2.0\u001b[39m,\u001b[38;5;241m3.0\u001b[39m], requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1.0,2.0,3.0], requires_grad=True)\n",
    "tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97be1732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffbd427d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1254,  1.9643],\n",
       "        [-1.1533, -0.5007],\n",
       "        [ 0.2953, -0.2281],\n",
       "        [ 0.5739, -0.4234],\n",
       "        [ 1.4096, -0.8122]], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 21.2 Preprocessing Data for Neural Networks\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# create feature\n",
    "features = np.array([[-100.1, 3240.1],\n",
    "                     [-200.2, -234.1],\n",
    "                     [5000.5, 150.1],\n",
    "                     [6000.6, -125.1],\n",
    "                     [9000.9, -673.1]])\n",
    "\n",
    "# create scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# convert to a tensor\n",
    "features_standardized_tensor = torch.from_numpy(features_scaled)\n",
    "\n",
    "# show features\n",
    "features_standardized_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4dbfd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.12541308,  1.96429418],\n",
       "       [-1.15329466, -0.50068741],\n",
       "       [ 0.29529406, -0.22809346],\n",
       "       [ 0.57385917, -0.42335076],\n",
       "       [ 1.40955451, -0.81216255]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c2d3080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1254,  1.9643],\n",
       "        [-1.1533, -0.5007],\n",
       "        [ 0.2953, -0.2281],\n",
       "        [ 0.5739, -0.4234],\n",
       "        [ 1.4096, -0.8122]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch_features = torch.tensor([[-100.1, 3240.1],\n",
    "                               [-200.2, -234.1],\n",
    "                               [5000.5, 150.1],\n",
    "                               [6000.6, -125.1],\n",
    "                               [9000.9, -673.1]], requires_grad=True)\n",
    "\n",
    "\n",
    "# Compute the mean and standard deviation\n",
    "mean = torch_features.mean(0, keepdim=True)\n",
    "standard_deviation = torch_features.std(0, unbiased=False, keepdim=True)\n",
    "\n",
    "# Standardize the features using the mean and standard deviation\n",
    "torch_features_standardized = torch_features - mean\n",
    "torch_features_standardized /= standard_deviation\n",
    "\n",
    "# Show standardized features\n",
    "torch_features_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d92774c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3940.3403,  471.5800]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0473e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNeuralNet(\n",
       "  (fc1): Linear(in_features=10, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 21.3 Designing a Neural Network\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# define a neural network\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "# Initialize the neural network\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# Define loss function, optimizer\n",
    "# Binary cross-entropy\n",
    "loss_criterion = nn.BCELoss()      # loss function for binary classify\n",
    "\n",
    "# RMSprob is an optimization algorithm using gradient to update weights\n",
    "optimizer = torch.optim.RMSprop(network.parameters())\n",
    "\n",
    "# show the network\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28c5d31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNeuralNet(\n",
       "  (sequential): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# define a neural network using 'sequential\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate and view the network\n",
    "SimpleNeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3122b10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \tLoss: 0.19006994366645813\n",
      "Epoch 2 \tLoss: 0.14092367887496948\n",
      "Epoch 3 \tLoss: 0.03935524821281433\n",
      "Test Loss: 0.06877756863832474 \tTest Accuracy: 0.9700000286102295\n"
     ]
    }
   ],
   "source": [
    "# 21.4 Training a Binary Classifier\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create training and test sets\n",
    "features, target = make_classification(n_classes=2,\n",
    "                                       n_features=10,\n",
    "                                       n_samples=1000)\n",
    "features_train , features_test, target_train, target_test = train_test_split(\n",
    "                          features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "\n",
    "# set random seed\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequentail = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequentail(x)\n",
    "        return x\n",
    "    \n",
    "# Initialize neural network\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# Define loss function, optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.RMSprop(network.parameters())\n",
    "\n",
    "# Define data loader\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# Compile the model using torch 2.0's optimizer\n",
    "network = torch.compile(network, backend=\"eager\")\n",
    "\n",
    "# train neural network\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for bach_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()            # compute gradient\n",
    "        optimizer.step()           # update parameters\n",
    "    print(\"Epoch\", epoch+1, \"\\tLoss:\", loss.item())\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = network(x_test)\n",
    "    test_loss = criterion(output, y_test)\n",
    "    test_accuracy = (output.round() == y_test).float().mean()\n",
    "    print(\"Test Loss:\", test_loss.item(), \"\\tTest Accuracy:\",\n",
    "    test_accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9a31da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hasadi/venv/lib/python3.10/site-packages/torch/_dynamo/utils.py:2753: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return fn()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \tLoss: 0.8022043108940125\n",
      "Epoch 2 \tLoss: 0.775616466999054\n",
      "Epoch 3 \tLoss: 0.7751265168190002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hasadi/venv/lib/python3.10/site-packages/torch/_dynamo/utils.py:2753: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return fn()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.8105322122573853 \tTest Accuracy: 0.8199999928474426\n"
     ]
    }
   ],
   "source": [
    "# 21.5 Training a Multiclass Classifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.optim import RMSprop\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "EPOCHS = 3\n",
    "N_CLASSES = 3\n",
    "\n",
    "# Create training and test sets\n",
    "features, target = make_classification(n_classes=N_CLASSES,\n",
    "                                       n_informative=9,\n",
    "                                       n_redundant=0,\n",
    "                                         n_features=10,\n",
    "                                           n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "                            features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "# y_train = torch.nn.functional.one_hot(torch.from_numpy(target_train).long(),\n",
    "#                                       num_classes=N_CLASSES ).float()\n",
    "y_train = torch.from_numpy(target_train).long()\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.nn.functional.one_hot(torch.from_numpy(target_test).long(),\n",
    "                                      num_classes=N_CLASSES ).float()\n",
    "\n",
    "# Define a neural network using `Sequential`\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequentail = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 3),\n",
    "            torch.nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequentail(x)\n",
    "        return x\n",
    "    \n",
    "# Initialize neural network\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# define loss function, optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# define data loader\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# compile the model using torch optimizer\n",
    "network = torch.compile(network)\n",
    "\n",
    "# train neural network\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch\", epoch+1, \"\\tLoss:\", loss.item())\n",
    "\n",
    "# evaluate neuarl network\n",
    "with torch.no_grad():\n",
    "    output = network(x_test)\n",
    "    test_loss = criterion(output, y_test)\n",
    "    test_accuracy = (output.round() == y_test).float().mean()\n",
    "    print(\"Test Loss:\", test_loss.item(), \"\\tTest Accuracy:\",test_accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb73e2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 0, 0, 2, 1, 2, 1, 2, 1, 0, 1, 1, 1, 2, 2, 2, 2, 1, 0, 2, 2, 0,\n",
       "        0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 2, 2, 2, 2, 1, 0, 1, 1, 0, 0, 1, 1, 2,\n",
       "        1, 2, 0, 2, 0, 0, 2, 0, 1, 1, 0, 1, 1, 2, 2, 1, 0, 1, 0, 0, 1, 2, 2, 0,\n",
       "        2, 2, 2, 0, 2, 0, 1, 0, 2, 0, 2, 2, 1, 0, 1, 1, 0, 1, 0, 2, 0, 1, 2, 2,\n",
       "        0, 1, 2, 2, 2, 1, 1, 2, 0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 0, 1, 0, 0, 2, 2,\n",
       "        0, 0, 1, 0, 2, 1, 2, 2, 2, 2, 1, 0, 1, 2, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 2, 0, 2, 1, 0, 2, 0, 2, 2, 1, 1, 2, 1, 1, 2, 0, 0, 1, 0, 0, 1,\n",
       "        1, 1, 2, 0, 2, 0, 2, 2, 0, 1, 0, 1, 0, 1, 0, 2, 0, 2, 2, 0, 0, 2, 1, 1,\n",
       "        2, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 0, 2, 1, 1, 2, 0, 2, 1, 1, 1, 1, 2, 0,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 2, 1, 0, 2, 1, 2, 2, 1, 1, 1, 1, 0, 2, 2,\n",
       "        1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 2, 2, 0, 1, 1, 2, 2, 0, 2, 0, 2, 2, 1, 1,\n",
       "        0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 2, 2, 1, 2, 1, 0, 0, 1, 1, 2, 2, 1, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 1, 2, 2, 0, 0, 1, 2, 0, 0, 2, 2, 0, 1, 2, 0, 2, 0, 0,\n",
       "        0, 1, 2, 1, 1, 1, 2, 0, 0, 1, 1, 2, 1, 1, 0, 2, 1, 2, 2, 0, 2, 0, 0, 0,\n",
       "        1, 1, 1, 2, 2, 1, 2, 1, 1, 0, 2, 2, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 2, 0, 0, 0, 0, 2, 0, 2, 2, 2, 0, 2, 0, 1, 1, 2, 1, 0, 1, 2, 1, 2, 0,\n",
       "        0, 2, 2, 1, 1, 2, 2, 2, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 1, 2, 1, 2, 0, 2,\n",
       "        0, 2, 0, 1, 1, 0, 0, 0, 2, 2, 2, 1, 2, 1, 1, 0, 2, 0, 0, 1, 1, 2, 1, 1,\n",
       "        0, 1, 0, 1, 2, 2, 2, 2, 0, 0, 1, 0, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 0,\n",
       "        2, 1, 2, 1, 1, 1, 0, 1, 1, 1, 2, 2, 0, 0, 1, 0, 0, 2, 2, 2, 2, 0, 0, 2,\n",
       "        2, 1, 2, 1, 2, 2, 2, 1, 1, 0, 0, 2, 2, 2, 2, 2, 0, 1, 2, 1, 2, 0, 2, 2,\n",
       "        0, 2, 0, 1, 2, 1, 0, 2, 0, 1, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 1, 0,\n",
       "        1, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 0, 0, 1, 0, 2, 2, 2, 0, 2, 2,\n",
       "        1, 0, 2, 1, 2, 1, 1, 1, 0, 1, 0, 1, 2, 2, 0, 2, 0, 1, 0, 0, 1, 2, 2, 2,\n",
       "        2, 0, 1, 1, 2, 0, 1, 2, 0, 2, 1, 2, 2, 0, 1, 0, 2, 2, 2, 0, 1, 2, 1, 2,\n",
       "        0, 1, 0, 1, 2, 0, 0, 1, 1, 2, 0, 0, 0, 0, 0, 1, 1, 0, 2, 2, 1, 1, 0, 0,\n",
       "        1, 2, 1, 2, 0, 2, 0, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 2, 1, 2,\n",
       "        1, 1, 2, 0, 1, 0, 1, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 2, 1, 0,\n",
       "        2, 1, 2, 0, 1, 0, 0, 0, 2, 1, 0, 2, 0, 0, 2, 1, 2, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 0, 2, 0, 1, 0, 0, 1, 1, 0, 0, 2, 2,\n",
       "        2, 0, 1, 2, 2, 2, 2, 1, 0, 0, 1, 1, 2, 1, 0, 1, 0, 1, 2, 0, 0, 2, 1, 2,\n",
       "        1, 1, 2, 1, 0, 1, 1, 1, 1, 2, 2, 2, 1, 0, 0, 2, 1, 1, 1, 2, 2, 2, 2, 1,\n",
       "        2, 2, 2, 2, 0, 1, 0, 1, 1, 0, 0, 1, 2, 0, 0, 2, 0, 1, 2, 2, 0, 1, 1, 0,\n",
       "        2, 1, 2, 1, 1, 1, 2, 2, 0, 0, 0, 2, 0, 1, 2, 1, 0, 2, 2, 1, 1, 0, 0, 0,\n",
       "        0, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 0, 0, 1, 2, 2, 0, 2, 0, 0,\n",
       "        0, 1, 0, 0, 2, 2, 0, 1, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 2, 1, 0, 1, 0, 2,\n",
       "        1, 0, 2, 0, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 0, 2, 0, 2, 2, 2, 2, 0,\n",
       "        0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee2b62de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tLoss: 10764.02734375\n",
      "Epoch: 2 \tLoss: 1356.5101318359375\n",
      "Epoch: 3 \tLoss: 504.96636962890625\n",
      "Epoch: 4 \tLoss: 199.11314392089844\n",
      "Epoch: 5 \tLoss: 191.20834350585938\n",
      "Test MSE 162.24508666992188\n"
     ]
    }
   ],
   "source": [
    "# 21.6 Training a Regressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "EPOCHS=5\n",
    "\n",
    "# Create training and test sets\n",
    "features, target = make_regression(n_features=10, n_samples=1000)\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "                            features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1,1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1,1)\n",
    "\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# Initialize neural network\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# Define loss function, optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = RMSprop(network.parameters()) \n",
    "\n",
    "# define data loader\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# compile the model using torch optimizer\n",
    "network = torch.compile(network)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch:\", epoch+1, \"\\tLoss:\", loss.item())\n",
    "\n",
    "\n",
    "# evaluate neuarl network\n",
    "with torch.no_grad():\n",
    "    output = network(x_test)\n",
    "    test_loss = float(criterion(output, y_test))\n",
    "    print(\"Test MSE\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9881d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tLoss 0.19006989896297455\n",
      "Epoch: 2 \tLoss 0.14092369377613068\n",
      "Epoch: 3 \tLoss 0.03935524821281433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 21.7 Making Predictions\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create training and test sets\n",
    "features, target = make_classification(n_classes=2,\n",
    "                                       n_features=10,\n",
    "                                         n_samples=1000)\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "                            features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# convert data to pytorch tensors\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# Define a neural network using `Sequential`\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(10, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),   \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# Initialize neural network\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# define loss function , optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# define data loader\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# compile the model using torch optimizer\n",
    "network = torch.compile(network)\n",
    "\n",
    "# train neural network\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch:\", epoch+1, \"\\tLoss\", loss.item())\n",
    "\n",
    "# evaluate neural network\n",
    "with torch.no_grad():\n",
    "    prediced_class = network.forward(x_train).round()\n",
    "\n",
    "prediced_class[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7395adc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAaQZJREFUeJzt3Xl8E2XiBvBnkibpfdOTlrZQbigFSrkUFRQQERAVXJTKKq7IYbfqT/DCuyiKyLEiuKKrINcKInJXQESwQClyFAR60vu+adpkfn9UotkW6Jk3bZ7v55OP7WQyeaaAeTrzzjuSLMsyiIiIiCyIQnQAIiIiIlNjASIiIiKLwwJEREREFocFiIiIiCwOCxARERFZHBYgIiIisjgsQERERGRxrEQHMEd6vR4ZGRlwcHCAJEmi4xAREVEDyLKM0tJS+Pj4QKG4+TEeFqB6ZGRkwM/PT3QMIiIiaoK0tDR07NjxpuuwANXDwcEBQO0P0NHRUXAaIiIiaoiSkhL4+fkZPsdvhgWoHtdPezk6OrIAERERtTENGb7CQdBERERkcViAiIiIyOKwABEREZHF4RggIiIyG3q9HlqtVnQMMlMqlQpKpbJFtsUCREREZkGr1SIpKQl6vV50FDJjzs7O8PLyavY8fSxAREQknCzLyMzMhFKphJ+f3y0nsSPLI8syKioqkJOTAwDw9vZu1vZYgIiISLiamhpUVFTAx8cHtra2ouOQmbKxsQEA5OTkwMPDo1mnw1ixiYhIOJ1OBwBQq9WCk5C5u16Qq6urm7UdFiAiIjIbvP8i3UpL/R1hASIiIiKLwwJEREREFocFiIiIyIwEBARg6dKlDV7/4MGDkCQJRUVFrZapPWIBIiIiagJJkm76eP3115u03ePHj+Opp55q8PpDhw5FZmYmnJycmvR+DdXeihYvgzexmppi5OV9By+v6aKjEBFRM2RmZhq+3rhxI1577TVcvHjRsMze3t7wtSzL0Ol0sLK69cduhw4dGpVDrVbDy8urUa8hHgEyqZqaMsTG9sCFCxEoLDwoOg4RkdnT6cpv8rjWiHUrG7RuY3h5eRkeTk5OkCTJ8P2FCxfg4OCAXbt2YcCAAdBoNPj5559x5coVTJgwAZ6enrC3t0dYWBj2799vtN3/PQUmSRI+++wzTJo0Cba2tggODsb27dsNz//vkZkvvvgCzs7O2LNnD3r06AF7e3uMGTPGqLDV1NRg3rx5cHZ2hpubG1588UVERERg4sSJjfoZ/FVhYSGmT58OFxcX2NraYuzYsbh06ZLh+ZSUFIwfPx4uLi6ws7NDr169sHPnTsNrp02bhg4dOsDGxgbBwcFYu3Ztk7M0BI8AmZCVlT3c3SciI+MTXL48DwMGxEGh4B8BEdGNHD5sf8PnXF3vRd++Pxi+P3LEA3p9Rb3rOjmNQGjoQcP3x44FoLo6r856d9whNz1sPebPn48PPvgAQUFBcHFxQVpaGu69916888470Gg0+M9//oPx48fj4sWL8Pf3v+F23njjDbz//vtYvHgxli9fjmnTpiElJQWurq71rl9RUYEPPvgAX331FRQKBR599FE8//zzWLduHQDgvffew7p167B27Vr06NEDH3/8MbZt24Y777yzyfv6+OOP49KlS9i+fTscHR3x4osv4t5778X58+ehUqkwe/ZsaLVa/PTTT7Czs8P58+cNR8leffVVnD9/Hrt27YK7uzsuX76MysrKW7xj8/DT18QCA99CTs5GlJefQUbGKnTsOEd0JCIiaiVvvvkm7r77bsP3rq6uCAkJMXz/1ltvYevWrdi+fTvmzLnx58Hjjz+ORx55BADw7rvvYtmyZYiNjcWYMWPqXb+6uhqrVq1C586dAQBz5szBm2++aXh++fLlWLBgASZNmgQAWLFiheFoTFNcLz5HjhzB0KFDAQDr1q2Dn58ftm3bhoceegipqamYPHky+vTpAwAICgoyvD41NRWhoaEYOHAggNqjYK2NBcjEVCo3BAa+jUuXnkFy8qvw8JgCtbpx53uJiCzFbbeV3eRZ49sgDBuWc5N1jUd8DB6c3ORMjXH9A/26srIyvP766/jhhx+QmZmJmpoaVFZWIjU19abb6du3r+FrOzs7ODo6Gu6JVR9bW1tD+QFq75t1ff3i4mJkZ2dj0KBBhueVSiUGDBjQ5BvRJiQkwMrKCuHh4YZlbm5u6NatGxISEgAA8+bNw6xZs7B3716MGjUKkydPNuzXrFmzMHnyZMTFxeGee+7BxIkTDUWqtXAMkAA+Pk/Bzi4ENTVFSEp6RXQcIiKzpVTa3eRh3Yh1bRq0bkuzszPe5vPPP4+tW7fi3XffxeHDhxEfH48+ffpAq9XedDsqlcroe0mSblpW6ltfllv29F5jPfnkk0hMTMRjjz2GM2fOYODAgVi+fDkAYOzYsUhJScE///lPZGRkYOTIkXj++edbNQ8LkACSpERwcO0fembmGpSWnhSciIiITOHIkSN4/PHHMWnSJPTp0wdeXl5ITk42aQYnJyd4enri+PHjhmU6nQ5xcXFN3maPHj1QU1ODX3/91bAsPz8fFy9eRM+ePQ3L/Pz88PTTT+Pbb7/Fc889hzVr1hie69ChAyIiIvD1119j6dKlWL16dZPzNARPgQni7HwbPDymQZKsoFb7io5DREQmEBwcjG+//Rbjx4+HJEl49dVXm3zaqTnmzp2L6OhodOnSBd27d8fy5ctRWFjYoPtsnTlzBg4ODobvJUlCSEgIJkyYgJkzZ+LTTz+Fg4MD5s+fD19fX0yYMAEAEBkZibFjx6Jr164oLCzEgQMH0KNHDwDAa6+9hgEDBqBXr16oqqrCjh07DM+1FhYggXr0+BKSpLz1ikRE1C4sWbIEf//73zF06FC4u7vjxRdfRElJiclzvPjii8jKysL06dOhVCrx1FNPYfTo0VAqb/2ZdPvttxt9r1QqUVNTg7Vr1+LZZ5/FfffdB61Wi9tvvx07d+40nI7T6XSYPXs2rl69CkdHR4wZMwYfffQRgNq5jBYsWIDk5GTY2Njgtttuw4YNG1p+x/9CkkWfFDRDJSUlcHJyQnFxMRwdHU32vrKsYyEiIot07do1JCUlITAwENbW1rd+AbUovV6PHj164OGHH8Zbb70lOs5N3ezvSmM+v3kEyAxUVibhypUo2Nh0RefO74mOQ0RE7VxKSgr27t2LESNGoKqqCitWrEBSUhL+9re/iY5mMixAZqC8/Bzy8rZBklTw9n4CtrZdRUciIqJ2TKFQ4IsvvsDzzz8PWZbRu3dv7N+/v9XH3ZgTFiAz4O5+H1xd70VBwU5cvhyJPn1+aNBANCIioqbw8/PDkSNHRMcQipfBm4kuXZZCklQoKNiF/Pwfbv0CIiIiajIWIDNhaxuMjh2jAACXL0fWuckfERERtRwWIDPSqdMrUKt9cO3aFVy9+pHoOERERO0WC5AZsbKyR+fO7wMAsrPXQZZ1ghMRERG1TxwEbWY8PP4Gna4Cnp6Pck4gIiKiVsICZGYkSYKPz0zRMYiIiNo1ngIzY7KsQ3b2euj1NaKjEBHR/5Ak6aaP119/vVnb3rZtW4utR3UJL0ArV65EQEAArK2tER4ejtjY2Buue+7cOUyePBkBAQGQJAlLly6ts45Op8Orr76KwMBA2NjYoHPnznjrrbfQ1u74IcsyfvttDBISpiEz81PRcYiI6H9kZmYaHkuXLoWjo6PRsueff150RLoJoQVo48aNiIqKwsKFCxEXF4eQkBCMHj0aOTk59a5fUVGBoKAgLFq0CF5eXvWu89577+GTTz7BihUrkJCQgPfeew/vv/8+li9f3pq70uIkSYK7+yQAQFLSq9Bq8wQnIiKiv/Ly8jI8nJycIEmS0bINGzagR48esLa2Rvfu3fGvf/3L8FqtVos5c+bA29sb1tbW6NSpE6KjowEAAQEBAIBJkyZBkiTD942l1+vx5ptvomPHjtBoNOjXrx92797doAyyLOP111+Hv78/NBoNfHx8MG/evKb9oMyU0DFAS5YswcyZMzFjxgwAwKpVq/DDDz/g888/x/z58+usHxYWhrCwMACo93kA+OWXXzBhwgSMGzcOQO1fpG+++eamR5aqqqpQVVVl+F7EnXnr4+39FDIyPkV5+W9ISnoF3bqtEh2JiMgkZFlGRXWFkPe2Vdk2ezb+devW4bXXXsOKFSsQGhqKU6dOYebMmbCzs0NERASWLVuG7du3Y9OmTfD390daWhrS0tIAAMePH4eHhwfWrl2LMWPGNOgO7fX5+OOP8eGHH+LTTz9FaGgoPv/8c9x///04d+4cgoODb5rhv//9Lz766CNs2LABvXr1QlZWFk6fPt2sn4m5EVaAtFotTp48iQULFhiWKRQKjBo1CkePHm3ydocOHYrVq1fj999/R9euXXH69Gn8/PPPWLJkyQ1fEx0djTfeeKPJ79laFAorBAcvR3z8CGRmroaPzz/g4BAqOhYRUaurqK6AfbS9kPcuW1AGO7Vds7axcOFCfPjhh3jggQcAAIGBgTh//jw+/fRTREREIDU1FcHBwRg+fDgkSUKnTp0Mr+3QoQMAwNnZ+YZnOxrigw8+wIsvvoipU6cCqD1DcuDAASxduhQrV668aYbU1FR4eXlh1KhRUKlU8Pf3x6BBg5qcxRwJOwWWl5cHnU4HT09Po+Wenp7Iyspq8nbnz5+PqVOnonv37lCpVAgNDUVkZCSmTZt2w9csWLAAxcXFhsf1BmwOnJ1vh4fHVAAyLl2a2+bGMhERWZry8nJcuXIFTzzxBOzt7Q2Pt99+G1euXAEAPP7444iPj0e3bt0wb9487N27t0UzlJSUICMjA8OGDTNaPmzYMCQkJNwyw0MPPYTKykoEBQVh5syZ2Lp1K2pq2tcFOe3uMvhNmzZh3bp1WL9+PXr16oX4+HhERkbCx8cHERER9b5Go9FAo9GYOGnDBQUtRl7edpSUHEFOznp4et64zBERtQe2KluULSgT9t7NUVZWm3vNmjUIDw83eu766az+/fsjKSkJu3btwv79+/Hwww9j1KhR2LJlS7PeuzFulsHPzw8XL17E/v37sW/fPjzzzDNYvHgxDh06BJVKZbKMrUlYAXJ3d4dSqUR2drbR8uzs7GYd8nvhhRcMR4EAoE+fPkhJSUF0dPQNC5C5s7buiE6dXkZ+/g7Y2vYQHYeIqNVJktTs01CieHp6wsfHB4mJiTc9++Do6IgpU6ZgypQpePDBBzFmzBgUFBTA1dUVKpUKOl3T7wbg6OgIHx8fHDlyBCNGjDAsP3LkiNGprJtlsLGxwfjx4zF+/HjMnj0b3bt3x5kzZ9C/f/8m5zInwgqQWq3GgAEDEBMTg4kTJwKoHbEeExODOXPmNHm7FRUVUCiMz+wplUro9frmxBXOz+//4O8/H5IkfOYCIiK6hTfeeAPz5s2Dk5MTxowZg6qqKpw4cQKFhYWIiorCkiVL4O3tjdDQUCgUCmzevBleXl5wdnYGUHsBT0xMDIYNGwaNRgMXF5cbvldSUhLi4+ONlgUHB+OFF17AwoUL0blzZ/Tr1w9r165FfHw81q1bBwA3zfDFF19Ap9MhPDwctra2+Prrr2FjY2M0TqitE3oKLCoqChERERg4cCAGDRqEpUuXory83HBV2PTp0+Hr62u4LE+r1eL8+fOGr9PT0xEfHw97e3t06dIFADB+/Hi888478Pf3R69evXDq1CksWbIEf//738XsZAtRKIz/qGRZbvZVCkRE1DqefPJJ2NraYvHixXjhhRdgZ2eHPn36IDIyEgDg4OCA999/H5cuXYJSqURYWBh27txp+AX+ww8/RFRUFNasWQNfX18kJyff8L2ioqLqLDt8+DDmzZuH4uJiPPfcc8jJyUHPnj2xfft2BAcH3zKDs7MzFi1ahKioKOh0OvTp0wfff/893NzcWvxnJYokCx5Vu2LFCixevBhZWVno168fli1bZjhnescddyAgIABffPEFACA5ORmBgYF1tjFixAgcPHgQAFBaWopXX30VW7duRU5ODnx8fPDII4/gtddeg1qtblCmkpISODk5obi4GI6Oji2yny2lpqYUKSlvo7Lyd/TuvVV0HCKiFnHt2jUkJSUhMDAQ1tbWouOQGbvZ35XGfH4LL0DmyJwLUEXF7zh+vDdkuRp9+uyAm9s40ZGIiJqNBYgaqqUKEAeUtDG2tl3RseM/AQCXL0dCr6+6xSuIiIjof7EAtUGdOr0CtdoblZWXkZZ24wkeiYiIqH4sQG2QlZUDgoLeBwCkpLyNa9euCk5ERETUtrAAtVGentPg6DgUen0FEhP/T3QcIqIWwWGpdCst9XeEBaiNkiQJwcHLAUjIy9uOqqoM0ZGIiJrs+gzJWq1WcBIydxUVtTfJbe6M1O3uVhiWxMGhP7p1+wwuLvdAo/ERHYeIqMmsrKxga2uL3NxcqFSqOhPaEsmyjIqKCuTk5MDZ2dlQmpuKBaiN8/Zu2xM8EhEBtUe1vb29kZSUhJSUFNFxyIw5Ozs365ZZ17EAtSOFhQdgb98XKlX7mamTiCyHWq1GcHAwT4PRDalUqmYf+bmOBaidSEx8Gamp78LHZxa6dv2X6DhERE2iUCg4ESKZBE+ythOurvcAADIyPkVpabzYMERERGaOBaidcHYegQ4dpgDQ4/LlebyUlIiI6CZYgNqRzp0XQ6GwRXHxYeTkbBAdh4iIyGyxALUj1tZ+6NTpJQDAlSvPo6amTHAiIiIi88QC1M507PgcrK2DoNVmIDX1XdFxiIiIzBILUDujVFqjS5ePoNF0hL19f9FxiIiIzBIvg2+H3NzGw8XlbiiVNqKjEBERmSUeAWqHJEkyKj+8IoyIiMgYC1A7Jst6ZGZ+jlOnboNeXyU6DhERkdlgAWrHdLpyJCW9jJKSI7h6danoOERERGaDBagds7JyQFDQ+wCA5OS3UFWVLjgRERGReWABauc8PafB0XEI9PpyXLnyoug4REREZoEFqJ2TJAWCg5cDkJCTsw5FRT+LjkRERCQcC5AFcHAYAG/vJwEAly/PhSzrBCciIiISiwXIQgQGvgMrK2eUlcWjqOiQ6DhERERCcSJEC6FWd0DXrmtgbe0HR8dw0XGIiIiEYgGyIB4eD4qOQEREZBZ4CsxCVVZeQUXFRdExiIiIhGABskA5OZsQG9sLFy/O5G0yiIjIIrEAWSBHx8GQJAWKiw8jJ2ej6DhEREQmxwJkgayt/eHvvwAAcOXK86ipKROciIiIyLRYgCyUn98LsLYOhFabjtTUaNFxiIiITIoFyEIpldbo3HkJACAt7QNUVFwWnIiIiMh0WIAsmLv7BLi43ANZ1uLKlSjRcYiIiExGeAFauXIlAgICYG1tjfDwcMTGxt5w3XPnzmHy5MkICAiAJElYunRpveulp6fj0UcfhZubG2xsbNCnTx+cOHGilfag7ZIkCV26fAyl0hEODmGQZb3oSERERCYhtABt3LgRUVFRWLhwIeLi4hASEoLRo0cjJyen3vUrKioQFBSERYsWwcvLq951CgsLMWzYMKhUKuzatQvnz5/Hhx9+CBcXl9bclTbLzq47hgy5ioCAVyFJwvswERGRSUiywIlgwsPDERYWhhUrVgAA9Ho9/Pz8MHfuXMyfP/+mrw0ICEBkZCQiIyONls+fPx9HjhzB4cOHm5yrpKQETk5OKC4uhqOjY5O3Q0RERKbTmM9vYb/ya7VanDx5EqNGjfozjEKBUaNG4ejRo03e7vbt2zFw4EA89NBD8PDwQGhoKNasWXPT11RVVaGkpMToYYmKig7j1KnbUFWVIToKERFRqxJWgPLy8qDT6eDp6Wm03NPTE1lZWU3ebmJiIj755BMEBwdjz549mDVrFubNm4cvv/zyhq+Jjo6Gk5OT4eHn59fk92+rZFlGYuKLKC7+GYmJL4qOQ0RE1Kra3aAPvV6P/v37491330VoaCieeuopzJw5E6tWrbrhaxYsWIDi4mLDIy0tzYSJzUPtgOhlACRkZ3+N4uIjoiMRERG1GmEFyN3dHUqlEtnZ2UbLs7OzbzjAuSG8vb3Rs2dPo2U9evRAamrqDV+j0Wjg6Oho9LBEjo4D4e39BADg0qW5kGWd4EREREStQ1gBUqvVGDBgAGJiYgzL9Ho9YmJiMGTIkCZvd9iwYbh40fgu57///js6derU5G1aksDAd6BUOqGs7BQyM/8tOg4REVGrEHoKLCoqCmvWrMGXX36JhIQEzJo1C+Xl5ZgxYwYAYPr06ViwYIFhfa1Wi/j4eMTHx0Or1SI9PR3x8fG4fPnPWYz/+c9/4tixY3j33Xdx+fJlrF+/HqtXr8bs2bNNvn9tkVrtgcDANwAAiYkvobq6QHAiIiKilif0MngAWLFiBRYvXoysrCz069cPy5YtQ3h4OADgjjvuQEBAAL744gsAQHJyMgIDA+tsY8SIETh48KDh+x07dmDBggW4dOkSAgMDERUVhZkzZzY4k6VfBq/XV+PEiVBUVJxDUNBi+Ps/LzoSERHRLTXm81t4ATJHll6AAKCo6Cdcu5YKT89pkCRJdBwiIqJbasznt5WJMlEb4+x8u+gIRERErabdXQZPLa+mpgSlpadExyAiImoxLEB0U2VlpxEb2w1nz94Pna5cdBwiIqIWwQJEN2Vj0xUKhTWqqq4iJSVadBwiIqIWwQJEN6VU2qBz548AAGlpi1FZeUVwIiIiouZjAaJbcnefABeXuyHLWly+HCU6DhERUbOxANEt1d4n7GNIkhXy87cjP3+36EhERETNwgJEDWJn1wO+vvMAAJcvPwu9Xis4ERERUdOxAFGDBQQshFrtBQeHMF4RRkREbRonQqQGs7JyRFjYOahUrqKjEBERNQuPAFGjsPwQEVF7wAJETXLtWgrOnXsIxcW/iI5CRETUaCxA1CQpKe8iN3cLLl2aB1nWiY5DRETUKCxA1CSBgW9CqXREWdlJZGZ+LjoOERFRo7AAUZOo1Z4ICHgDAJCU9BKqqwsFJyIiImo4FiBqMl/f2bC17Ynq6jwkJy8UHYeIiKjBWICoyRQKFbp0+RgAkJ7+L5SVnRGciIiIqGFYgKhZXF1Hwd39AQA6pKbybvFERNQ2cCJEarbOnT+EnV1v+Pv/n+goREREDcICRM1mYxOAwMA3RMcgIiJqMJ4CoxYlyzqUlp4UHYOIiOimWICoxVRXF+LkyXDExQ1DZWWi6DhEREQ3xAJELcbKyhlWVs6Q5SpcvhwlOg4REdENsQBRi5EkCcHBywAokZ//HQoK9oiOREREVC8WIGpRdnY90bHjXADApUvPQq/XCk5ERERUFwsQtbiAgNehUnmgsvIi0tOXi45DRERUBwsQtTgrKycEBdVOipic/AaqqjIFJyIiIjLGAkStwsvrcTg4hMHWtgd0uhLRcYiIiIxwIkRqFZKkQJ8+O6BSuUOS2LOJiMi8sABRq1GrPURHICIiqhd/NadWV1NThsTEl5CV9aXoKERERAB4BIhMIDv7P0hNjYZK1QFubhOgUjmLjkRERBaOR4Co1Xl7z4StbQ9UV+ciOfl10XGIiIhYgKj1KRQqdOmyDACQnr4CZWVnBSciIiJLZxYFaOXKlQgICIC1tTXCw8MRGxt7w3XPnTuHyZMnIyAgAJIkYenSpTfd9qJFiyBJEiIjI1s2NDWKq+souLs/AECHy5fnQZZl0ZGIiMiCCS9AGzduRFRUFBYuXIi4uDiEhIRg9OjRyMnJqXf9iooKBAUFYdGiRfDy8rrpto8fP45PP/0Uffv2bY3o1EidO38ISdKgqOgAysriRMchIiILJrwALVmyBDNnzsSMGTPQs2dPrFq1Cra2tvj888/rXT8sLAyLFy/G1KlTodFobrjdsrIyTJs2DWvWrIGLi0trxadGsLEJgJvbWABAfv5OwWmIiMiSCS1AWq0WJ0+exKhRowzLFAoFRo0ahaNHjzZr27Nnz8a4ceOMtn0jVVVVKCkpMXpQ6/D0jIC//3y4ud0nOgoREVkwoZfB5+XlQafTwdPT02i5p6cnLly40OTtbtiwAXFxcTh+/HiD1o+OjsYbb7zR5PejhuvQYSI6dJgoOgYREVk44afAWlpaWhqeffZZrFu3DtbW1g16zYIFC1BcXGx4pKWltXJKIiIiEknoESB3d3colUpkZ2cbLc/Ozr7lAOcbOXnyJHJyctC/f3/DMp1Oh59++gkrVqxAVVUVlEql0Ws0Gs1NxxNRy9LpKlBUdADV1YXw8npUdBwiIrJAQo8AqdVqDBgwADExMYZler0eMTExGDJkSJO2OXLkSJw5cwbx8fGGx8CBAzFt2jTEx8fXKT9keiUlR3HmzH1ITHwBsqwXHYeIiCyQ8FthREVFISIiAgMHDsSgQYOwdOlSlJeXY8aMGQCA6dOnw9fXF9HR0QBqB06fP3/e8HV6ejri4+Nhb2+PLl26wMHBAb179zZ6Dzs7O7i5udVZTmI4OQ2HQmEHrTYLZWWn4eAQKjoSERFZGOEFaMqUKcjNzcVrr72GrKws9OvXD7t37zYMjE5NTYVC8eeBqoyMDISG/vmB+cEHH+CDDz7AiBEjcPDgQVPHpyZQKDRwcbkL+fnfo6BgFwsQERGZnCRzSt46SkpK4OTkhOLiYjg6OoqO0y6lp3+CS5eegZPTcISGHhYdh4iI2oHGfH63u6vAqG1wda2dELG4+Ciqq4vEhiEiIovDAkRC2NgEwNa2OwAdCgv3i45DREQWhgWIhLl+FKik5JjgJEREZGmED4Imy+XrOw/e3k/B1rab6ChERGRhWIBIGBubANERiIjIQvEUGBEREVkcFiASqrw8AefOPYQzZyaKjkJERBaEp8BIKIVCjdzcLZAkK9TUlMDKivMuERFR6+MRIBLKxqYzbGyCIcs1vByeiIhMhgWIhLt+OXxBwW7BSYiIyFKwAJFwfxagXeCdWYiIyBRYgEg4Z+cRUCisUVV1FeXl50THISIiC8ACRMIplTZwdr4TQO1RICIiotbGq8DILLi5jUN1dQHUai/RUYiIyAKwAJFZ8PF5Br6+s0XHICIiC8FTYGQWJEkSHYGIiCwICxCZlZqaYpSWnhIdg4iI2jkWIDIbxcVH8fPPbjh7dgIvhyciolbFAkRmw94+BJJkhaqqNFRUJIiOQ0RE7RgLEJkNpdIWzs53AODl8ERE1LpYgMisuLnVzgqdn88CRERErYcFiMzK9dtiFBcfRk1NmeA0RETUXrEAkVmxsQmGtXUgZFmLoqIfRcchIqJ2igWIzIokSUY3RyUiImoNnAmazI6XVwTs7HrDze1e0VGIiKidYgEis+PoOAiOjoNExyAionaMp8CIiIjI4rAAkVmqrs5HevpKJCW9JjoKERG1QyxAZJa02hxcujQHqanvQacrFx2HiIjaGRYgMku2tt2h0XT643L4g6LjEBFRO8MCRGZJkiTOCk1ERK2GBYjM1l/nA+Ld4YmIqCWxAJHZcna+E5KkwrVriaisvCQ6DhERtSMsQGS2rKwc4OR0GwDOCk1ERC3LLArQypUrERAQAGtra4SHhyM2NvaG6547dw6TJ09GQEAAJEnC0qVL66wTHR2NsLAwODg4wMPDAxMnTsTFixdbcQ+otbi6joUkWaGqKkN0FCIiakeEF6CNGzciKioKCxcuRFxcHEJCQjB69Gjk5OTUu35FRQWCgoKwaNEieHl51bvOoUOHMHv2bBw7dgz79u1DdXU17rnnHpSX83LqtsbHZyaGDctH587viY5CRETtiCQLHl0aHh6OsLAwrFixAgCg1+vh5+eHuXPnYv78+Td9bUBAACIjIxEZGXnT9XJzc+Hh4YFDhw7h9ttvr/N8VVUVqqqqDN+XlJTAz88PxcXFcHR0bPxOERERkcmVlJTAycmpQZ/fQo8AabVanDx5EqNGjTIsUygUGDVqFI4ePdpi71NcXAwAcHV1rff56OhoODk5GR5+fn4t9t7UcnS6a6IjEBFRO9GkApSWloarV68avo+NjUVkZCRWr17dqO3k5eVBp9PB09PTaLmnpyeysrKaEq0OvV6PyMhIDBs2DL179653nQULFqC4uNjwSEtLa5H3ppZRUXERJ08OwokTIaKjEBFRO9GkAvS3v/0NBw4cAABkZWXh7rvvRmxsLF5++WW8+eabLRqwuWbPno2zZ89iw4YNN1xHo9HA0dHR6EHmQ632QVnZKVRW/o6Kisui4xARUTvQpAJ09uxZDBo0CACwadMm9O7dG7/88gvWrVuHL774osHbcXd3h1KpRHZ2ttHy7OzsGw5wbow5c+Zgx44dOHDgADp27Njs7ZEYtZfDDwfAy+GJiKhlNKkAVVdXQ6PRAAD279+P+++/HwDQvXt3ZGZmNng7arUaAwYMQExMjGGZXq9HTEwMhgwZ0pRoAABZljFnzhxs3boVP/74IwIDA5u8LTIPf50VmoiIqLmaVIB69eqFVatW4fDhw9i3bx/GjBkDAMjIyICbm1ujthUVFYU1a9bgyy+/REJCAmbNmoXy8nLMmDEDADB9+nQsWLDAsL5Wq0V8fDzi4+Oh1WqRnp6O+Ph4XL7856mR2bNn4+uvv8b69evh4OCArKwsZGVlobKysim7S2bgegEqKjoInY5/jkRE1DxNugz+4MGDmDRpEkpKShAREYHPP/8cAPDSSy/hwoUL+Pbbbxu1vRUrVmDx4sXIyspCv379sGzZMoSHhwMA7rjjDgQEBBhOrSUnJ9d7RGfEiBE4ePBg7U5JUr3vs3btWjz++OO3zNOYy+jINGRZxtGjftBq09G37264uo4WHYmIiMxMYz6/mzwPkE6nQ0lJCVxcXAzLkpOTYWtrCw8Pj6Zs0mywAJmnixdnIjPzM/j6Povg4KWi4xARkZlpzOe3VVPeoLKyErIsG8pPSkoKtm7dih49emD0aP5mTq3D3f0B1NSUwMXlTtFRiIiojWtSAZowYQIeeOABPP300ygqKkJ4eDhUKhXy8vKwZMkSzJo1q6VzEsHNbSzc3MaKjkFERO1AkwZBx8XF4bbbau/SvWXLFnh6eiIlJQX/+c9/sGzZshYNSERERNTSmlSAKioq4ODgAADYu3cvHnjgASgUCgwePBgpKSktGpDor2RZRnn5eeTmNm6gPRER0V81qQB16dIF27ZtQ1paGvbs2YN77rkHAJCTk8NBw9SqysvP4vjxXkhIeIz3BiMioiZrUgF67bXX8PzzzyMgIACDBg0yTFq4d+9ehIaGtmhAor+ys+sNtdoben0FiosPi45DRERtVJMK0IMPPojU1FScOHECe/bsMSwfOXIkPvrooxYL197IsowVsStwKf+S6ChtliRJcHWtnXizoGC34DRERNRWNakAAYCXlxdCQ0ORkZFhuDP8oEGD0L179xYL1968eehNzN01F1O2TMG1Gp6+aSreFoOIiJqrSQVIr9fjzTffhJOTEzp16oROnTrB2dkZb731FvR6fUtnbDee7P8k3G3dcSrrFJ7f+7zoOG2Wi8vdAJSoqEjAtWscdE9ERI3XpAL08ssvY8WKFVi0aBFOnTqFU6dO4d1338Xy5cvx6quvtnTGdsPX0RdfTfoKALDy+EpsOb9FcKK2SaVyhpNT7biz/HweBSIiosZrUgH68ssv8dlnn2HWrFno27cv+vbti2eeeQZr1qwx3LOL6jemyxi8OOxFAMAT259AYmGi4ERt0/VxQIWFewUnISKitqhJBaigoKDesT7du3dHQUFBs0O1d2/d+RaG+g1FSVUJpmyZgqqaKtGR2hwPj2no02cnevT4WnQUIiJqg5pUgEJCQrBixYo6y1esWIG+ffs2O1R7p1KqsGHyBrjauOJExgm8uP9F0ZHaHBubALi5jYVSaSs6ChERtUFNuhv8oUOHMG7cOPj7+xvmADp69CjS0tKwc+dOw20y2ipT3Q1+x+87MP6b8QCArVO2YmL3ia32XkRERO1dYz6/m3QEaMSIEfj9998xadIkFBUVoaioCA888ADOnTuHr776qkmhLdF9Xe/Dc0OeAwDM+G4GkouSxQZqY7TaHFy58iLOnn1QdBQiImpjmnQE6EZOnz6N/v37Q6fTtdQmhTDVESAAqNZV47a1t+HX9F8xyHcQDs84DLVS3arv2V5UVxfgyJEOAPQYPDgF1tb+oiMREZFArX4EiFqOSqnChgc3wNnaGbHpsViwf4HoSG2GSuUKR8fBADgrNBERNQ4LkBkIcA7AFxO+AAAsObYE31/8XmygNoSzQhMRUVOwAJmJCd0nIDI8EgAQsS0CqcWpYgO1EX/OB7Qfer1WcBoiImorrBqz8gMPPHDT54uKipqTxeK9d/d7OJJ2BMczjmPqlqk49PghqJQq0bHMmoNDf6hUHqiuzkFx8RG4uNwpOhIREbUBjToC5OTkdNNHp06dMH369NbK2u6plWpsfHAjnDROOHr1KF758RXRkcyeJCng6joaAE+DERFRwzXqCNDatWtbKwf9IdAlEJ9P+ByTN03G+7+8jxEBI3Bv8L2iY5k1V9exKCjYA4XCRnQUIiJqI1r0Mvj2wpSXwd/I3J1zseL4CrjZuCH+6Xh0dOwoJEdboNfXQJIUkCQOaSMismS8DL4d+OCeD9Dfuz/yK/PxyH8fQY2+RnQks6VQWLH8EBFRo/BTw0xprDTY+OBGOKgd8HPqz1h4YKHoSGZPlvWorEwWHYOIiNoAFiAz1sW1Cz67/zMAQPTP0dh7Za/gROarsjIZv/zigxMnQqDXV4uOQ0REZo4FyMw93OthPD3gaciQ8ei3jyKjNEN0JLNUexsMHXS6EpSUHBUdh4iIzBwLUBvw0ZiPEOIZgtyKXPztv3/jeKB6SJICLi68HJ6IiBqGBagNsLayxqaHNsFebY9DKYfw5qE3RUcyS25utbfFyM9nASIioptjAWojurp1xaf3fQoAePunt7E/cb/gRObHxeUeABLKy0+jqoqnComI6MZYgNqQv/X5G2b2n2kYD5RVliU6kllRqzvAwWEgAKCgYI/gNEREZM5YgNqYj8d8jD4efZBdno1p306DTq8THcms8O7wRETUECxAbYyNygabHtoEO5Udfkz6Ee8cfkd0JLPSocMD8PP7P/j6zhMdhYiIzJhZFKCVK1ciICAA1tbWCA8PR2xs7A3XPXfuHCZPnoyAgABIkoSlS5c2e5ttTXf37vhk3CcAgDcOvYGDyQfFBjIj9vYh6Nz5PTg7DxcdhYiIzJjwArRx40ZERUVh4cKFiIuLQ0hICEaPHo2cnJx616+oqEBQUBAWLVoELy+vFtlmW/RYyGOY0W8G9LIef/vv35BT3n72jYiIqLUJvxlqeHg4wsLCsGLFCgCAXq+Hn58f5s6di/nz59/0tQEBAYiMjERkZGSLbRMwj5uhNkS5thyDPhuE87nncU/ne7Br2i4oeE8s6PVVKCz8EeXlv8Hf/0XRcYiIyETazM1QtVotTp48iVGjRhmWKRQKjBo1CkePNm0236Zss6qqCiUlJUaPtsBObYdND26CjZUN9l7Zi0U/LxIdySzU1BTjzJl7kZg4H1VVvFKOiIjqElqA8vLyoNPp4OnpabTc09MTWVlN++Bqyjajo6Ph5ORkePj5+TXpvUXo5dELK+9dCQB49cCrOJxyWHAi8dRqD9jbDwAAFBbycngiIqqL50sALFiwAMXFxYZHWlqa6EiN8ni/x/FY38egl/WY+t+pyC3PFR1JOM4KTURENyO0ALm7u0OpVCI7O9toeXZ29g0HOLfGNjUaDRwdHY0ebYkkSfjXuH+hu3t3ZJRmYPq26dDLetGxhLo+H1Bh4V7IMudKIiIiY0ILkFqtxoABAxATE2NYptfrERMTgyFDhpjNNtsCe7U9Nj24CdZW1th9eTcWH1ksOpJQDg6DYGXljJqaQpSUtJ8pEIiIqGUIPwUWFRWFNWvW4Msvv0RCQgJmzZqF8vJyzJgxAwAwffp0LFiwwLC+VqtFfHw84uPjodVqkZ6ejvj4eFy+fLnB22yv+nj2wbIxywAAL//4Mo6kHhGcSByFwuqPe4NxVmgiIqrLSnSAKVOmIDc3F6+99hqysrLQr18/7N692zCIOTU1FQrFnz0tIyMDoaGhhu8/+OADfPDBBxgxYgQOHjzYoG22Z0/2fxIHkg/gm7PfYOp/pyL+H/Fws3UTHUsIV9exyM3dhLKyeNFRiIjIzAifB8gctZV5gG6ktKoUA1YPwKWCS7iv633YPnU7JEkSHcvkqquLoNVmwNa2h0XuPxGRpWkz8wBR63DQOGDzQ5uhUWqw4/cdWHJ0iehIQqhUzrCz68nyQ0REdbAAtVMhXiFYOmYpAGB+zHwcu3pMbCDBeKCTiIj+igWoHfvHgH/g4V4Po0Zfg6lbpqKwslB0JJPTavNw7txUxMZ24+XwRERkwALUjkmShDXj16CzS2ekFKdgxnczLO5IiJWVMwoKdqOy8hJKSo6LjkNERGaCBaidc9Q4YtNDm6BWqvHdxe+w7NdloiOZlEJhBVfXuwEABQW7BachIiJzwQJkAfp798eH93wIAHhh3ws4nm5ZR0KuzwrN+YCIiOg6FiALMTtsNh7o8QCq9dV4eMvDKLpWJDqSybi6jgEAlJYeh1bL+6QRERELkMWQJAn/vv/fCHQORHJRMp7Y/oTFjAfSaHxgZxcCQEZh4V7RcYiIyAywAFkQZ2tnbHxwI1QKFb5N+BYrj68UHclkrh8F4t3hiYgIYAGyOGG+YXj/7vcBAM/tfQ5xmXGCE5mGm9s4ODgMhINDf9FRiIjIDPBWGPVo67fCuBVZljFp4yR8d/E7dHbpjLh/xMFR0/72k4iILAtvhUE3JUkSPp/wOfyd/HGl8Apmfj/TYsYDERERASxAFsvVxhUbH9wIK4UVNp3bhE9Pfio6kknU1JSgsPCA6BhERCQYC5AFG9xxMBaNXAQAiNwdifiseLGBWplWm4cjR9xx+vQoVFfni45DREQCsQBZuKghUbiv632o0lXh4c0Po7SqVHSkVqNWu8PWthsAPQoK9omOQ0REArEAWThJkvDFhC/g5+iHSwWX8PQPT7fr8UCcFZqIiAAWIALgZuuGDQ9ugFJSYv2Z9fj3qX+LjtRqrs8HVFCwG7KsF5yGiIhEYQEiAMBQv6F45653AABzd83Fb9m/CU7UOpychkOptEd1dQ7Kyk6JjkNERIKwAJHBC8NewNguY3Gt5hoe3vwwyrRloiO1OIVCDWfnkQA4KzQRkSVjASIDhaTAlxO/hI+DDy7mX8QzPzzTLscDubldHwe0W3ASIiIShQWIjHSw64BvJn8DhaTAV799hS/ivxAdqcW5uY1HcPAK9OjxH9FRiIhIEBYgquP2TrfjzTveBADM3jkb53LOCU7UsjQaH/j6zoaNTZDoKEREJAgLENVrwW0LcHfQ3aisqcTDWx5GubZcdCQiIqIWwwJE9VJICnw16St42XvhfO55zN01V3SkFqXTVSIj41MkJETwcngiIgvEAkQ35GnvifUPrIdCUmBt/Fp8dfor0ZFajCQpcPnyc8jO/g/Kyk6LjkNERCbGAkQ3dWfgnVg4YiEAYNYPs3Ah74LgRC1DodDAxeUuAJwVmojIErEA0S29fNvLuCvwLpRXl+PhzQ+jsrpSdKQWwdtiEBFZLhYguiWlQol1D6yDp50nzuScwbO7nxUdqUVcL0DFxUdRXV0kNgwREZkUCxA1iJe9F9Y9sA4SJKyJW4P1Z9aLjtRsNjYBsLXtDkCHwsL9ouMQEZEJsQBRg40MGolXbn8FAPCPHf/A7/m/C07UfDwNRkRkmViAqFEWjliIEZ1GoExbhoc3P4xrNddER2qW2gKkhE5XKjoKERGZEAsQNYpSocT6yevRwbYDTmefxj93/1N0pGZxdh6BYcPy0KvXJtFRiIjIhFiAqNF8HHzw1aTaOYFWnVyFTefabnlQKNRQqZxFxyAiIhNjAaImGd1lNBYMXwAAeHL7k7hccFlwouarqeFpMCIiS2EWBWjlypUICAiAtbU1wsPDERsbe9P1N2/ejO7du8Pa2hp9+vTBzp07jZ4vKyvDnDlz0LFjR9jY2KBnz55YtWpVa+6CRXrzzjcx3H84SrWlmLJlCqpqqkRHapKamlKcPDkYR450QE1Nieg4RERkAsIL0MaNGxEVFYWFCxciLi4OISEhGD16NHJycupd/5dffsEjjzyCJ554AqdOncLEiRMxceJEnD171rBOVFQUdu/eja+//hoJCQmIjIzEnDlzsH37dlPtlkWwUljhm8nfwM3GDXGZcXh+7/OiIzWJlZUDamoKIMtVvByeiMhCSLIsyyIDhIeHIywsDCtWrAAA6PV6+Pn5Ye7cuZg/f36d9adMmYLy8nLs2LHDsGzw4MHo16+f4ShP7969MWXKFLz66quGdQYMGICxY8fi7bffrrPNqqoqVFX9efSipKQEfn5+KC4uhqOjY4vta3u189JOjFs/DgCw5aEtmNxzsuBEjXfp0rNIT18Gb+8n0a3bGtFxiIioCUpKSuDk5NSgz2+hR4C0Wi1OnjyJUaNGGZYpFAqMGjUKR48erfc1R48eNVofAEaPHm20/tChQ7F9+3akp6dDlmUcOHAAv//+O+655556txkdHQ0nJyfDw8/PrwX2znLcG3wvXhj6AgDgie1PILEwUXCixvtzPqDdEPw7ARERmYDQApSXlwedTgdPT0+j5Z6ensjKyqr3NVlZWbdcf/ny5ejZsyc6duwItVqNMWPGYOXKlbj99tvr3eaCBQtQXFxseKSlpTVzzyzPO3e9gyEdh6C4qhhTt0yFVqcVHalRnJ1HQKGwRlXVVZSXnxMdh4iIWpnwMUCtYfny5Th27Bi2b9+OkydP4sMPP8Ts2bOxf3/94zs0Gg0cHR2NHtQ4KqUKGx7cABdrFxzPOI4X970oOlKjKJU2cHa+EwBnhSYisgRCC5C7uzuUSiWys7ONlmdnZ8PLy6ve13h5ed10/crKSrz00ktYsmQJxo8fj759+2LOnDmYMmUKPvjgg9bZEQIA+Dv548uJXwIAlv66FNsubBMbqJF4WwwiIsshtACp1WoMGDAAMTExhmV6vR4xMTEYMmRIva8ZMmSI0foAsG/fPsP61dXVqK6uhkJhvGtKpRJ6vb6F94D+1/hu4xE1OAoAMOO7GUguShYbqBHc3O5Fhw4PwsvrcdFRiIiolVmJDhAVFYWIiAgMHDgQgwYNwtKlS1FeXo4ZM2YAAKZPnw5fX19ER0cDAJ599lmMGDECH374IcaNG4cNGzbgxIkTWL16NQDA0dERI0aMwAsvvAAbGxt06tQJhw4dwn/+8x8sWbJE2H5akuhR0fg57WfEpsdi6pap+GnGT1Ar1aJj3ZKNTWf06rVZdAwiIjIB4WOArp+aeu2119CvXz/Ex8dj9+7dhoHOqampyMzMNKw/dOhQrF+/HqtXr0ZISAi2bNmCbdu2oXfv3oZ1NmzYgLCwMEybNg09e/bEokWL8M477+Dpp582+f5ZIrVSjY0PboSztTN+Tf8VL8W8JDoSERGREeHzAJmjxswjQDe27cI2TNo4CQDw/SPf476u9wlOdGuyLKOy8ncUFh6Aj88/IEmS6EhERNRAbWYeIGrfJnafiHmD5gEAIrZFIK3Y/KcX0Ouv4cSJfrh0aRYqKs6LjkNERK2EBYha1ft3v48B3gNQUFmAqf+dimpdtehIN6VU2sDJaQSA2kkRiYiofWIBolalsdJg00Ob4KhxxC9pv+DVA6/e+kWCubnVXg6fn8/L4YmI2isWIGp1QS5B+Pf9/wYAvHfkPey6ZN7F4vp8QMXFh1FTUyY4DRERtQYWIDKJB3s+iGcGPgMAmLRxEob8ewie+eEZrDm5BicyTuBazTXBCf9kYxMMa+sgyLIWRUU/io5DREStQPg8QGQ5Phz9Ic7lnsOhlEM4dvUYjl09ZnhOKSnRo0MPhHqF1j68Q9HPqx+crZ1NnlOSJLi6jkFGxr9QULAL7u73mzwDERG1Ll4GXw9eBt969LIel/Iv4VTWKZzKPFX736xTyKvIq3f9QOdAhHqHGhUjb3vvVr88PS9vB86eHQ8bm24ID7/Qqu9FREQtozGf3yxA9WABMi1ZlpFemm5UiE5lnkJKcUq963vYeRgKUT+vfgj1DkUX1y5QSC13Rlenq0Bh4Y9wcbkTSqVdi22XiIhaDwtQM7EAmYeCygLEZ8XjVOYpxGfX/jchLwF6ue493ezV9gjxDDEcJQr1CkUvj15t4hYcRETUMliAmokFyHxVVlfiTM4Zo6NFv2X/Vu8gapVChV4evYyOFvXz6gcHjYOA5ERE1NpYgJqJBahtqdHX4GLeRcOps+tHiwqvFda7fhfXLkZjikK9QuFp71lnPb2+CsnJr6OwMAb9+h3gqTAiIjPHAtRMLEBtnyzLSC1OrTPY+mrJ1XrX97b3Nhps3c+rHwKdA/Hrr0GoqkpBnz474OY2zsR7QUREjcEC1EwsQO1Xbnlu7biivwy2/j3/d8io+8/AUeOIbo528FdnIqzjSIwNXYIe7j2gUqoEJCciolthAWomFiDLUqYtw5nsM0ZHi87knIFWp62zrkapQW+P3kanz/p69oWdmqfHiIhEYwFqJhYgqtZVIyEvASfSf8HOuNm4VKZHcqU9SrR1b40hQUI39261l+T/ZWyRu627gORERJaLBaiZWIDor+LjR6Ko6EcEdV6Carv76wy2zizLrPd1HR071hls7e/k3+qTOBIRWSoWoGZiAaK/Sk39AImJL8DVdQz69q17I9fssuw6g60vF1yud1su1i4I8QqBv5M/vO294WXvBS97L6OvHTWOLElERE3AAtRMLED0V+Xl5xAffyfc3SeiW7fVDXpNSVUJTmedNhSi+Kx4nMs5h2p99S1fa2Nl82cxcvCGl91fvv5LYfKw8+CAbCKiv2ABaiYWIPqr2n8iMqRm3mqjqqYK53PP40zOGWSUZiCrLAtZZVnILMs0fF1SVdKobbrbut/wSNJfC5OTxolHlYio3WMBaiYWIBKlXFuO7PLs2mJUmllvScosy0R2WTZ0sq7B27W2sq6/JP1PYfKw8+DtQ4iozWIBaiYWIKqPLMuoqDgPO7teoqNAL+uRX5FvXIyuF6Zy4/JUXFXcqG272bjVOd1W39fO1s48qkREZoUFqJlYgOh/6fU1iI0NxrVryRg06BJsbbuIjtRgFdUVyC7LrnskqTQTWeV/fp1dno0afU2Dt6tRaho0VsnT3pNHlYjIJBrz+W1lokxEbZpCYQVr6wBcu5aMgoLdsLWdIzpSg9mqbBHoEohAl8CbrqeX9SioLDA6elTf6bessiwUXStCla4KKcUpSClOuWUGVxtXo6NHPdx7YGTQSAz0GQgrBf83RESmxyNA9eARIKpPaur7SEx8Ea6u96Jv3x9ExxHqWs0145J0g/FKWWVZN73yzVHjiDsC7sDIwJEYGTgSPTv05Gk1ImoyngJrJhYgqk9Z2RmcONEXCoUNhg0rgFJpLTqS2dPLehRWFhoVo4zSDPya/isOJB1A4bVCo/W97L0MZWhk0Ej4O/kLSk5EbRELUDOxAFF9ZFnG0aN+0GrT0bfvbri6jhYdqU3T6XWIz4pHTFIM9ifux8+pP6OyptJonS6uXTAqcBRGBo3EnQF3ws3WTVBaImoLWICaiQWIbuTixZnIzPwMHTtGokuXj0THaVeqaqpw9OpR7E/cj5ikGBxPP250qb8ECf28+mFU0CiMDByJ4f7DeRNaIjLCAtRMLEB0I7m53+LcucmwsemG8PALouO0a8XXivFTyk+GQnQu95zR8yqFCkP9hhpOl4X5hHFmbCILxwLUTCxAdCM1NcVITn4Trq5j4eIykgN2TSizNBM/Jv2ImKQYxCTFILU41eh5B7UDRgSMMIwh6u3Rm38+RBaGBaiZWICIzJssy7hSeMVwdOjHpB9RUFlgtI6nnSfuCrzLcIQowDlATFgiMhkWoGZiASJqW/SyHqezThsK0eHUw6iorjBap7NLZ0MZuivwLrjbugtKS0SthQWomViA6GZkWY/CwhgUFOxBYODbvBzeDFXVVOHX9F8NhejXq7/WuXdaP69+htNlt3W6DfZqe0FpLUdh4UFoNL6wtQ0GAGi1eUhLWwx39/vh6DgYkqQUnJDaOhagZmIBopupvRzeF1ptJvr23QtX17tFR6JbKKkqwU8pPyEmsXb80JmcM0bPqxQqDO442HCEKNw3nAOqW1BJyQkkJb2EwsJ96NDhQfTqtRkAkJX1H1y4EAEAUKnc4ep6L9zcxsPVdTSsrBxERqY2qjGf3woTZbqplStXIiAgANbW1ggPD0dsbOxN19+8eTO6d+8Oa2tr9OnTBzt37qyzTkJCAu6//344OTnBzs4OYWFhSE1NrWdrRI0jSRJcXccAAAoKdgtOQw3hqHHEfV3vw0djPsJvs35D1nNZWP/AejwR+gQ6OXVCtb4ah1MP4/VDr+O2tbfB9X1XjFs/DkuOLsHprNPQy3rRu9AmlZefx9mzkxEXF4bCwn2QJCuoVJ6Q//h5WlsHwcPjEVhZOaO6Og/Z2f/B+fMP4cgRd5w+PRrl5QmC94DaM+FHgDZu3Ijp06dj1apVCA8Px9KlS7F582ZcvHgRHh4eddb/5ZdfcPvttyM6Ohr33Xcf1q9fj/feew9xcXHo3bs3AODKlSsYNGgQnnjiCTzyyCNwdHTEuXPnMHjw4Hq3+b94BIhuJSdnM86ffxi2tj0waNB50XGoGWRZRmJhouHqsh+TfkReRZ7ROh1sOxgGVI8KGnXL+6pZusrKZCQnv47s7K8A6AFI8PR8DAEBC2FjE1Rnfb2+GsXFR5Cf/z3y879HZeUlABKGDs2EWu0JACguPgJJsoKDQxgkySx+dycz1KZOgYWHhyMsLAwrVqwAAOj1evj5+WHu3LmYP39+nfWnTJmC8vJy7Nixw7Bs8ODB6NevH1atWgUAmDp1KlQqFb766qsmZWIBolupri7CkSPuAHQYPDgZ1tadREeiFqKX9TiTfcYwfuinlJ9QXl1utE6gc6DRgGoPu1v/YmVJUlPfQ2Ji7f+/3d0fQGDgm7Cz69Xg11dUXERJya/w8ppuWBYffxeKig5ApfKEm9u4P06V3Q2lkpNh0p/aTAHSarWwtbXFli1bMHHiRMPyiIgIFBUV4bvvvqvzGn9/f0RFRSEyMtKwbOHChdi2bRtOnz4NvV4PJycn/N///R9+/vlnnDp1CoGBgViwYIHRe/xVVVUVqqqqDN+XlJTAz8+PBYhu6tSp21Bc/DOCgz+Br+/TouNQK9HqtPj16q+GI0THrh5Djb7GaJ2+nn0NA6pv73Q7HDSWNX6luroAWm2moeTodBW4ePEJdOwYBUfHsGZvX5ZlJCQ8ivz876HTlRqWS5IGLi4j0aHDg/D2ntHs96G2r82MAcrLy4NOp4Onp6fRck9PT2RlZdX7mqysrJuun5OTg7KyMixatAhjxozB3r17MWnSJDzwwAM4dOhQvduMjo6Gk5OT4eHn59cCe0ft3Z/jgHYJTkKtSa1U47ZOt+H1O17H4RmHUfhiIX742w+IGhyFEM8QAMBv2b/ho2Mf4b5v7oPr+64Y/vlwLDywED+l/AStTit4D1pPTU0ZUlLewbFjQTh//m+GsT1KpS169vymRcoPUDvurmfPdRg2LA99++6Dr+88WFsHQparUFCwE7m5W4zWLys7C17fQ7diJTpAS9Pra/8BTpgwAf/85z8BAP369cMvv/yCVatWYcSIEXVes2DBAkRFRRm+v34EiOhmXF3HIinpFVRUXIQsy5x1uBH0ei1++2003N0nw8trOqys2s6RVnu1Pe4Nvhf3Bt8LAMgpz8GBpAOGI0SJhYk4knYER9KO4M2f3oStyha3d7rdMH6or2dfKFphDIte1qNGX2P0qNZV11lWo69Btb7+5Q19jbamEoXFR5BXEANtTQV0MqCwyoRr3jOQJZsGvU9Xt66NPmKmUKjh6joKrq6j0KXLUlRUnEde3vews+thWOfatVScONEHarUP3Nzug5vbeLi4jIRSadPiP3Nq24QWIHd3dyiVSmRnZxstz87OhpeXV72v8fLyuun67u7usLKyQs+ePY3W6dGjB37++ed6t6nRaKDRaJq6G2Sh7O37YeDA32Bnx1su3EphYQxyc7ciOHg5JElCbu5/UVR0EEVFB5GUtACeno/Bx+cZ2Nv3Fh210TzsPDCl9xRM6T0FAJBUmGQoQzGJMcityMXuy7ux+3LtFYPutu4Y3HEwrBRWDS4fNysT118jQ/QRj1wg8dMGr/3DpR/w0bGPoJSUGOQ7CCMDa8dTDfEbAmurW8+tJUkS7Ox61RlbVF5+DgqFHbTaDGRmrkZm5mooFDZwcbkbbm7j4e4+AWp1h0bvHbU/ZjEIetCgQVi+fDmA2iM4/v7+mDNnzg0HQVdUVOD77783LBs6dCj69u1rGAQ9dOhQdO7c2WgQ9KRJk2BjY4P169ffMhMHQRO1DJ2uAomJC5CevgwA0KPHN/D0nIqammJkZf0HGRn/QkXFnzeVdXK6Hb6+s+HuPgkKRdufh0cv63E256xh/qFDKYdQpi0zaQYrhZXhoVKojL43ek5Z/3N/fY2+Jg9lJUeglACV0hYujv3hYN8TKoW6Qdu6vj0ZMk5mnERMUgyuFF4xymttZY3h/sNxV8BdGBk0EgO8B0CpaNwEiTrdNRQVHTRcVVZVlWZ4rmfPDfDwqC2ren0VJEnNX2DakTYzCBqovQw+IiICn376KQYNGoSlS5di06ZNuHDhAjw9PTF9+nT4+voiOjoaQO1l8CNGjMCiRYswbtw4bNiwAe+++67RZfBbt27FlClTsHLlStx5553YvXs3IiMjcfDgQQwfPvyWmViAqLFkWc9Lc/9HSUksEhKmo7LyIgDAx+dpBAUthpXVnzMuy7KMoqIDSE9fiby87wDUztY8cOBvsLfvIyJ2q6rWVSM2PRa/Zf8GhaRocGFoTGH562sUkqJZH+6yLKOqKg3W1v6G78+cGQ8Xlzvh4/NMi5xWSilKMUw/EJMUg6wy4/GfThon3BFwh2Eagp4dejZqn2RZRnn5b8jL+x4FBTvRt+8uWFk5AQCSk99GZuZquLmN/+NU2Z1QKHg2oDVpdVqcyT6D2PRYdHHtgrs7t+xEsm2qAAHAihUrsHjxYmRlZaFfv35YtmwZwsPDAQB33HEHAgIC8MUXXxjW37x5M1555RUkJycjODgY77//Pu69916jbX7++eeIjo7G1atX0a1bN7zxxhuYMGFCg/KwAFFDybIeFy5EID9/FwYOPAVra44d0+urkZLyNlJS3gGgg1rtjW7dPoeb25ibvu7atavIzFyNiooL6NVrk2F5evpK2Nr2grPzCP6mbkJFRYeRlPQSyssTMHhwoknGacmyjIS8BEMZOph8EEXXiozWacmb3J46dTuKiw8bvlco7ODqeg/c3O6Hm9s4niprJr2sx6X8S4hNj0VseiyOZxxHfFY8qnS1V11P6zMNXz/wdYu+Z5srQOaGBYgaIy5uKEpKjqJr19Xw8ZkpOo5wZ89ORl7etwAAD49HEBy8AiqVa5O2pdXm4ujRjpBlLWxte8HX9xl4ej7G2yS0otLSOCQlvWK4ulGhsEbv3t/B1fUek2fR6XU4lXXKcArx59SfUVlTabROc+Zk0ukqUVgY88epsh3QajMMz1lZOWPo0FwoFO3uWqFWk16SblR2jmccR0lVSZ31XKxdMMh3EMYFj8Pc8LktmoEFqJlYgKgxkpPfQnLya3B3n4Tevb8VHUe4oqJDOHfuQQQHrzCMtWiqqqoMJCe/iezsr6DX197dXam0h6fndPj6zoadXc9bbIEaqrz8ApKTX0Nubu19uiTJCt7eT6JTp1eg0fgKTlerqqYKx64eMwwyj02PrTMnU2+P3kZzMjlZOzVo27KsR1nZKeTlbUd+/vewsQlGr14b/3hOxm+/3QNb255wcxsPZ+fboVCoW3z/2pLCykKcyDhhKDux6bHILMuss56NlQ36e/dHmE8YBvkOQphvGDq7dG61o7ksQM3EAkSNUVJyAnFxYVAqHTBsWJ7F/Y+xsjIZ5eW/wd39fsMyna68RWforR00/SXS0/9lGFMEAN27fwUvr0db7H0sVVVVFo4d84csV6P2thXTEBDwOmxsOouOdlOlVaU4nHoYMYkx+DH5R8RnxRs9r5SUGOgz0HCF2VC/obBRNWzckl5fbRiIX16egOPH/yzbSqUjXF1H/3GqbCxUKrcW2ydzVFldifiseKOyc6ngUp31lJISvT16G8rOIN9B6OXRC1YmPIrGAtRMLEDUGLKsxy+/eKG6OhchIQfg4nKH6EgmIcsysrLW4vLlSMiyDgMHnoatbZdWf8+ioh+Rnr4SBQV7MHhwsmGcRlnZWahUbtBovFs1Q3vxvyU1IWE6ampKEBj4VpsdgJ5XkYcDSQcMY4j+90Nao9RgmP8wwxVmA30GNujDWaerQEHBXsOpsurqnL88q0BQ0CL4+7/QwnsjRo2+Bgm5CUanss7knKlzpA0AOrt0RphvGAb51JadUO9Q2KpsBaT+EwtQM7EAUWMlJDyG7Oyv4ef3f+jc+T3RcVqdVpuNixefQn7+dgCAo+Mw9OjxFWxsTHeT0JqaYsPVPABw6tQIlJT8Anf3B+DrOxtOTrdx0HQ9qquLkJa2GOnpKzFgQCxsbbsCMD7i0V6kFacZXWGWUZph9LyD2gEjAkYYTpn19rj1nF6yrEdp6XHDqbLy8jPo02cH3NzGAagdQ5WdvQ5ubuPh5DTcrMcQybKMpKIkHE8/big7JzNPoqK6os66nnaetaew/ji6M9BnINxsze/IFwtQM7EAUWNlZ69HQsI02Nn1QVjYb6LjtKrc3G/x++//QHV1HiRJjcDAt+Dn9xwkqXFztbQkna4Cp0/fg5KSI4Zldna94ePzDDw9H+WgadQe8bl6dTnS0t5DTU0RAMDf/yUEBb0jNpiJyLKMi/kXDWXoQNIBFF4rNFqng20HoyvMAp0Db1mIKiuToVZ7QamsnbzxypX5SEur/SXIysoZrq5j4eZ2P1xdx0Clcm6VfWuonPIco7ITmx6L/Mr8Ous5qO3Qz7M7+nt0x21BkxDmGwY/Rz8UFu5FZWUS9PpK6PXX/nhc/1qLbt1WGbaRlPQaCgtj/medP183fHhxqwwXYAFqJhYgaiytNg9nzoyFq+sYBAS80S7nBJJlGRcvPoGsrLUAADu7vujR4yvY2/cVnOxPZWWnkZ7+L2Rnf/2XQdMOCAx8Bx07tuzVJm2FXq9FRsZqpKS8jerq2ln0bW17ITDwbbi7T7DYo2Q6vQ6ns08brjA7nHq4zpGPTk6dDGXozoA74e1w69OrBQX7kZ39FfLzf0BNzZ/lQpKs4OR0G3r23AC12vhKNVmWIctaQznQ6SoByEZHVIuKDqG6Os9onetfKxTW8Pd/3rBuYuLLyC0+jXOFufgtPw/nCotwrqgUmZXVdfJaSRK62Mvo5gB0/+PhZwsoJUChsMHtt//5M/ntt3EoKNh5w30fMaLG8IvQuXNTkJu76YbrDh9eZHQEt6WwADUTCxBR/ZKSXkVKyrvw938RAQELzXbSuOrqImRnXx80/Tt69FgPT89HANRe+ixJKrM+NdFSZFnGyZP9UVYWDwCwtg5EQMCb8PR8ROgRO3Ok1Wnx69VfDVeYHbt6rM64l54dehoGVN8RcAecrZ1vuD1Z1qGk5JjhVFlFRQJUKg8MHZpp+AXpxIn+qKi4AL3+GvA/tzKxsQlGePjvhu+PHw9BeXn9R5clKy/YB+2oHbeTEYvDVzYisbSyzs1RJAD+tgqMCH7UMG4H2S+jvGRf7fOSCgqFDRQKaygUNlAqbREWds5QklNS3kFp6cm/rGNt+FqptIGf34uGf1fFxceg1WbWWef66zQav1b5RZEFqJlYgIhq6XQVqK7OM8wErNdrUVZ2usXu8t3arg+adnK6zXC4PTX1fVy9ugw+Pv+At/dMaDT133ewrbr+v/S/fmilp69Ep06vwtv7CYu7SrGpyrRl+Dn1Z8MVZqcyTxndb00hKTDAe4DhlNkw/2E3HQBcWXkFlZVXjOZTio3thYqK83XWVShsYGPTGWFhZwzLEhIeR2XlZUDS4GqlHueKynG2sATnCguRUJgPrV5XZzs+9q7o7xGMUM9uGODVC6GefeFs4w5Hx4GGdWpqSiFJCigU1u2iFLMANRMLEDVVTU0Ziop+hKvr2DY/oLT2VhaPQam0Q//+x9rNB+fJk4NRWvorgNrTEu7uk/8YND28TZ8OkmUZhYX7kJj4EgID34Kb21gAMJxOUSrFXp3T1uVX5ONg8kHDoOqL+ReNnlcr1RjqN9RwhVmYTxhUypv/P6CyMhkAjI6M/PXeZLIsI7003Wjczq0mF/zrfDte9u2r3DcEC1AzsQBRU8iyjKNH/aDVpqNfv0Nwdr5ddKQmqb2VxVtISXkXtbey8EFISAzs7LqLjtYi9Poq5OZuQXr6v1BS8othuZ1dH3TsGAlv778LTNc0xcW/IDHxJRQXHwIAODndhtDQnwSnat+ullzFj0k/GgZVXy25avS8vdoet3e63XCFWR/PPlDc4pTPXycXjM2IxfH042YxuWBbwgLUTCxA1FTnzz+KnJx18Pefj6CgaNFxGq28/BwSEqajrCwOQPNvZWHuSktPISPjX8jOXge9vhIeHtPQs2fL3puoNZWWxv9x24ofAACSpIGv7zPw91/A+1iZkCzLuFRwyegKs/+9usrd1h13BtxpGEPU0bGjYXLB62XHXCcXbEtYgJqJBYiaKivra1y48Bjs7EIQFhYvOk6DybIeV68uRWLiS5DlKlhZuaJr10/g4fGw6GgmUV1diKysL+HsfBscHAYAqC2Dly49C1/fZ+Dmdr/ZDZpOTHwJqanXS7YS3t5/R6dOr/KGvGZAL+txOuu0oRD9lPITyqvLjdaRIBmNKbrOHCcXbEsa8/ltXv+iido4V9fRACSUl59GVVUGNBof0ZEaRJb1yM3dAlmugqvrWHTr9lmbyd4SVCoX+PlFGi1LT1+JoqIYFBXFQKPpCG/vf8Db+0mzGTR9vah5eExFQMAbhgkNSTyFpECodyhCvUPx3NDnoNVpcTz9uOEKs6NpR1Gtr24zkwu2VzwCVA8eAaLmOHlyEEpLj6Nbt3+b9XiS2rlHdIYjGxUVl1BUdADe3jM5lgDAtWspyMj4FJmZa1BdnQeg9jLhDh0mw8dnNpychpns56TV5iI19V3Y2ATD1/cZALV/fhUVCbwhbBtUUV2B4mvF8LL34r+1FsZTYM3EAkTNkZS0ECkpb6JDh4fQq9eNJwITqfZWFjNha9sNnTsvFh3HrOn1VcjJ2YyMjJUoKTkGAFCpOmDIkLRWnweppqYYaWkf4urVj6DTlUGlcsfgwckteqNZovakMZ/f7W+6WiLBXF1rLz8uKNgLfT03EBQtN/dbHD/eG/n53yM9fQWqqupeZUJ/Uig08PJ6FP37H8WAASfh5fUEfH3nGcqPLOuRlLQQFRUXb7GlhtPpKpCauhjHjgUhJeUt6HRlsLcfgB491kGh4HgQopbAI0D14BEgag5Z1iEj41O4uNzT6ndHb4zq6iJcvjwP2dlfAQDs7EL+uJVF27zzt7nIz9+JM2dqb4Tp4jIKPj6z4eZ2X5MHTefn78bFi3+HVltbTG1te/xx24pJPF1CdAscBE0kkCQpDeM0zEVBwX5cvDgDVVVXASjg7z//j1tZtI/JDUVSqTzg5jYe+fk7UFi4H4WF+6HR+MHH52l4ez9Z575Pt6LR+ECrzYJG0wmBgW/A0/PRdjFDL5G54RGgevAIELUnNTXFOHq0E3S6YtjYdEH37v+Bk9MQ0bHancrKZGRkrEJm5meGm2BKkgphYWdveIWWLMvIy/sOFRUX0KnTfMPygoI9cHa+w2zvtUZkrjgIuplYgKi5ZFlGVtbnyM//AcHB/xJ+6XRW1pcoKfkVnTsv5gDaVqbTXUNu7makp6+EXl+JgQPjDaeuiot/gb19CJRKOxQU7EdS0ksoLT0OSbJCWFiCWZ0yJWqLWICaiQWIWsKJEwNQVhaH7t2/gJdXhMne9/qtLJychv0xLxGJUl1dBJXKGUDtTSePHvUFoICtbTeUlsYCABQKW3Ts+E/4+T1vWJeImoZXgRGZgetXg+Xn7zLZe5aXn0Nc3GCkpLyFCxf+jpqaMpO9N9X110Jz7VoiVCoP6HTFKC2NhSSp4es7D4MHJyIo6G2WHyIT4yBoolbi5jYWqanvoLBwL2RZ16oDWeu7lUWXLh/Bysq+1d6TGsfePgTh4b+joGAPKirOo0OHB2Ft3Ul0LCKLxQJE1EocHMJhZeWMmppClJTEttrA48rKZFy48LjhTuCurvf+cSsL71Z5P2o6SVLAzW0s3NzGio5CZPF4CoyolSgUVnBxuQcAUFDQOqfBrl1LwYkTfVBcfAgKhR26dl2NPn12sPwQEd0CCxBRK/pzVujWKUDW1p3g5jYeTk7DERb2G3x8eB8vIqKG4CkwolZUexWWEgqFNfR6bYtMPJibuxVOTsMME+x167YGCoU1J8sjImoEFiCiVqTReGP48AJYWTV/OoXaW1nMRXb213Bzm4DevbdCkiTO60NE1AQsQEStrCXKz//eysLOrjcAPQAe9SEiagoWICITqa4uhJWVY6NOVel0FUhMnI/09OUAABub4D9uZTG4tWISEVkEDoImMoEzZ8bjyBF3lJQcb/BrKip+x4kToYby4+MzGwMHnmL5ISJqASxARCagUFgD0KOgYHeDX6NWe0GWtVCrfdG37x507bqC432IiFoICxCRCTT0cvjKykRcvz2flZUjevfejrCwM3B1vafVMxIRWRIWICITcHUdAwAoLT0OrTa3zvOyrENa2oeIje2JjIxVhuX29n2gUrmYLCcRkaUwiwK0cuVKBAQEwNraGuHh4YiNjb3p+ps3b0b37t1hbW2NPn36YOfOnTdc9+mnn4YkSVi6dGkLpyZqOI3GB3Z2IQBkFBbuNXqusjIJ8fF34cqV5yHLVSgqOmA4CkRERK1DeAHauHEjoqKisHDhQsTFxSEkJASjR49GTk5Ovev/8ssveOSRR/DEE0/g1KlTmDhxIiZOnIizZ8/WWXfr1q04duwYfHx8Wns3iG7p+lGg63eHl2UZmZn/xokTfVFc/JPhVhY9e27kbM5ERK1MkgX/qhkeHo6wsDCsWLECAKDX6+Hn54e5c+di/vz5ddafMmUKysvLsWPHDsOywYMHo1+/fli16s9TB+np6QgPD8eePXswbtw4REZGIjIyst4MVVVVqKqqMnxfUlICPz8/FBcXw9Gx+XO4EAFAUdEhxMffAZXKHQMHnsbvv/8D+fm1f4+dnIaje/cvYWMTJDglEVHbVVJSAicnpwZ9fgs9AqTVanHy5EmMGjXKsEyhUGDUqFE4evRova85evSo0foAMHr0aKP19Xo9HnvsMbzwwgvo1avXLXNER0fDycnJ8PDz82viHhHdmKPjUHh4TEVg4DuorExEfv4uSJIaQUGL0a/fQZYfIiITEjoRYl5eHnQ6HTw9PY2We3p64sKFC/W+Jisrq971s7KyDN+/9957sLKywrx58xqUY8GCBYiKijJ8f/0IEFFLUihU6NnzG8P3Xbt+AkfHIbC37y0wFRGRZWp3M0GfPHkSH3/8MeLi4ho8jkKj0UCj0bRyMiJjPj4zRUcgIrJYQk+Bubu7Q6lUIjs722h5dnY2vLy86n2Nl5fXTdc/fPgwcnJy4O/vDysrK1hZWSElJQXPPfccAgICWmU/iIiIqG0RWoDUajUGDBiAmJgYwzK9Xo+YmBgMGTKk3tcMGTLEaH0A2Ldvn2H9xx57DL/99hvi4+MNDx8fH7zwwgvYs2dP6+0MERERtRnCT4FFRUUhIiICAwcOxKBBg7B06VKUl5djxowZAIDp06fD19cX0dHRAIBnn30WI0aMwIcffohx48Zhw4YNOHHiBFavXg0AcHNzg5ubm9F7qFQqeHl5oVu3bqbdOSIiIjJLwgvQlClTkJubi9deew1ZWVno168fdu/ebRjonJqaCoXizwNVQ4cOxfr16/HKK6/gpZdeQnBwMLZt24bevTmQlIiIiBpG+DxA5qgx8wgQERGReWgz8wARERERicACRERERBaHBYiIiIgsDgsQERERWRwWICIiIrI4LEBERERkcViAiIiIyOKwABEREZHFYQEiIiIii8MCRERERBZH+L3AzNH1u4OUlJQITkJEREQNdf1zuyF3+WIBqkdpaSkAwM/PT3ASIiIiaqzS0lI4OTnddB3eDLUeer0eGRkZcHBwgCRJLbrtkpIS+Pn5IS0tzSJvtGrp+w/wZ8D9t+z9B/gzsPT9B1rvZyDLMkpLS+Hj4wOF4uajfHgEqB4KhQIdO3Zs1fdwdHS02L/4APcf4M+A+2/Z+w/wZ2Dp+w+0zs/gVkd+ruMgaCIiIrI4LEBERERkcViATEyj0WDhwoXQaDSiowhh6fsP8GfA/bfs/Qf4M7D0/QfM42fAQdBERERkcXgEiIiIiCwOCxARERFZHBYgIiIisjgsQERERGRxWIBMaOXKlQgICIC1tTXCw8MRGxsrOpLJ/PTTTxg/fjx8fHwgSRK2bdsmOpJJRUdHIywsDA4ODvDw8MDEiRNx8eJF0bFM6pNPPkHfvn0NE58NGTIEu3btEh1LmEWLFkGSJERGRoqOYhKvv/46JEkyenTv3l10LJNLT0/Ho48+Cjc3N9jY2KBPnz44ceKE6FgmERAQUOfvgCRJmD17tpA8LEAmsnHjRkRFRWHhwoWIi4tDSEgIRo8ejZycHNHRTKK8vBwhISFYuXKl6ChCHDp0CLNnz8axY8ewb98+VFdX45577kF5ebnoaCbTsWNHLFq0CCdPnsSJEydw1113YcKECTh37pzoaCZ3/PhxfPrpp+jbt6/oKCbVq1cvZGZmGh4///yz6EgmVVhYiGHDhkGlUmHXrl04f/48PvzwQ7i4uIiOZhLHjx83+vPft28fAOChhx4SE0gmkxg0aJA8e/Zsw/c6nU728fGRo6OjBaYSA4C8detW0TGEysnJkQHIhw4dEh1FKBcXF/mzzz4THcOkSktL5eDgYHnfvn3yiBEj5GeffVZ0JJNYuHChHBISIjqGUC+++KI8fPhw0THMxrPPPit37txZ1uv1Qt6fR4BMQKvV4uTJkxg1apRhmUKhwKhRo3D06FGByUiU4uJiAICrq6vgJGLodDps2LAB5eXlGDJkiOg4JjV79myMGzfO6P8HluLSpUvw8fFBUFAQpk2bhtTUVNGRTGr79u0YOHAgHnroIXh4eCA0NBRr1qwRHUsIrVaLr7/+Gn//+99b/KbjDcUCZAJ5eXnQ6XTw9PQ0Wu7p6YmsrCxBqUgUvV6PyMhIDBs2DL179xYdx6TOnDkDe3t7aDQaPP3009i6dSt69uwpOpbJbNiwAXFxcYiOjhYdxeTCw8PxxRdfYPfu3fjkk0+QlJSE2267DaWlpaKjmUxiYiI++eQTBAcHY8+ePZg1axbmzZuHL7/8UnQ0k9u2bRuKiorw+OOPC8vAu8ETmdjs2bNx9uxZixv/AADdunVDfHw8iouLsWXLFkRERODQoUMWUYLS0tLw7LPPYt++fbC2thYdx+TGjh1r+Lpv374IDw9Hp06dsGnTJjzxxBMCk5mOXq/HwIED8e677wIAQkNDcfbsWaxatQoRERGC05nWv//9b4wdOxY+Pj7CMvAIkAm4u7tDqVQiOzvbaHl2dja8vLwEpSIR5syZgx07duDAgQPo2LGj6Dgmp1ar0aVLFwwYMADR0dEICQnBxx9/LDqWSZw8eRI5OTno378/rKysYGVlhUOHDmHZsmWwsrKCTqcTHdGknJ2d0bVrV1y+fFl0FJPx9vauU/Z79OhhcacCU1JSsH//fjz55JNCc7AAmYBarcaAAQMQExNjWKbX6xETE2Nx4x8slSzLmDNnDrZu3Yoff/wRgYGBoiOZBb1ej6qqKtExTGLkyJE4c+YM4uPjDY+BAwdi2rRpiI+Ph1KpFB3RpMrKynDlyhV4e3uLjmIyw4YNqzP9xe+//45OnToJSiTG2rVr4eHhgXHjxgnNwVNgJhIVFYWIiAgMHDgQgwYNwtKlS1FeXo4ZM2aIjmYSZWVlRr/pJSUlIT4+Hq6urvD39xeYzDRmz56N9evX47vvvoODg4Nh7JeTkxNsbGwEpzONBQsWYOzYsfD390dpaSnWr1+PgwcPYs+ePaKjmYSDg0OdMV92dnZwc3OziLFgzz//PMaPH49OnTohIyMDCxcuhFKpxCOPPCI6msn885//xNChQ/Huu+/i4YcfRmxsLFavXo3Vq1eLjmYyer0ea9euRUREBKysBFcQIdeeWajly5fL/v7+slqtlgcNGiQfO3ZMdCSTOXDggAygziMiIkJ0NJOob98ByGvXrhUdzWT+/ve/y506dZLVarXcoUMHeeTIkfLevXtFxxLKki6DnzJliuzt7S2r1WrZ19dXnjJlinz58mXRsUzu+++/l3v37i1rNBq5e/fu8urVq0VHMqk9e/bIAOSLFy+KjiJLsizLYqoXERERkRgcA0REREQWhwWIiIiILA4LEBEREVkcFiAiIiKyOCxAREREZHFYgIiIiMjisAARERGRxWEBIiIiIovDAkREdAOSJGHbtm2iYxBRK2ABIiKz9Pjjj0OSpDqPMWPGiI5GRO0Ab4ZKRGZrzJgxWLt2rdEyjUYjKA0RtSc8AkREZkuj0cDLy8vo4eLiAqD29NQnn3yCsWPHwsbGBkFBQdiyZYvR68+cOYO77roLNjY2cHNzw1NPPYWysjKjdT7//HP06tULGo0G3t7emDNnjtHzeXl5mDRpEmxtbREcHIzt27cbnissLMS0adPQoUMH2NjYIDg4uE5hIyLzxAJERG3Wq6++ismTJ+P06dOYNm0apk6dioSEBABAeXk5Ro8eDRcXFxw/fhybN2/G/v37jQrOJ598gtmzZ+Opp57CmTNnsH37dnTp0sXoPd544w08/PDD+O2333Dvvfdi2rRpKCgoMLz/+fPnsWvXLiQkJOCTTz6Bu7u76X4ARNR0om9HT0RUn4iICFmpVMp2dnZGj3feeUeWZVkGID/99NNGrwkPD5dnzZoly7Isr169WnZxcZHLysoMz//www+yQqGQs7KyZFmWZR8fH/nll1++YQYA8iuvvGL4vqysTAYg79q1S5ZlWR4/frw8Y8aMltlhIjIpjgEiIrN155134pNPPjFa5urqavh6yJAhRs8NGTIE8fHxAICEhASEhITAzs7O8PywYcOg1+tx8eJFSJKEjIwMjBw58qYZ+vbta/jazs4Ojo6OyMnJAQDMmjULkydPRlxcHO655x5MnDgRQ4cObdK+EpFpsQARkdmys7Orc0qqpdjY2DRoPZVKZfS9JEnQ6/UAgLFjxyIlJQU7d+7Evn37MHLkSMyePRsffPBBi+clopbFMUBE1GYdO3aszvc9evQAAPTo0QOnT59GeXm54fkjR45AoVCgW7ducHBwQEBAAGJiYpqVoUOHDoiIiMDXX3+NpUuXYvXq1c3aHhGZBo8AEZHZqqqqQlZWltEyKysrw0DjzZs3Y+DAgRg+fDjWrVuH2NhY/Pvf/wYATJs2DQsXLkRERARef/115ObmYu7cuXjsscfg6ekJAHj99dfx9NNPw8PDA2PHjkVpaSmOHDmCuXPnNijfa6+9hgEDBqBXr16oqqrCjh07DAWMiMwbCxARma3du3fD29vbaFm3bt1w4cIFALVXaG3YsAHPPPMMvL298c0336Bnz54AAFtbW+zZswfPPvsswsLCYGtri8mTJ2PJkiWGbUVERODatWv46KOP8Pzzz8Pd3R0PPvhgg/Op1WosWLAAycnJsLGxwW233YYNGza0wJ4TUWuTZFmWRYcgImosSZKwdetWTJw4UXQUImqDOAaIiIiILA4LEBEREVkcjgEiojaJZ++JqDl4BIiIiIgsDgsQERERWRwWICIiIrI4LEBERERkcViAiIiIyOKwABEREZHFYQEiIiIii8MCRERERBbn/wHVt8vTAVrKjAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 21.8 Visualize Training History\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create training and test sets\n",
    "features, target = make_classification(n_classes=2,\n",
    "                                       n_features=10,\n",
    "                                       n_samples=1000)\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "                            features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# convert data to pytorch tensors\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# Define a neural network using `Sequential`\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(10, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),   \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x) \n",
    "        return x\n",
    "\n",
    "# Initialize neural network\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# define loss function , optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# define data loader\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# compile the model using torch optimizer\n",
    "network = torch.compile(network)\n",
    "\n",
    "# train neural network\n",
    "epochs = 8\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # train_output = network(x_train)\n",
    "        train_loss = criterion(output, target)\n",
    "        train_losses.append(train_loss.item())\n",
    "\n",
    "        test_output = network(x_test)\n",
    "        test_loss = criterion(test_output, y_test)\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "# visualize loss history\n",
    "epochs = range(0, epochs)\n",
    "plt.plot(epochs, train_losses, \"y--\")\n",
    "plt.plot(epochs, test_losses, \"g-\")\n",
    "plt.legend([\"Training Loss\", \"Test Loss\"])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e09b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test LossL 0.40308892726898193 \tTest Sccuracy: 0.9599999785423279\n"
     ]
    }
   ],
   "source": [
    "# 21.9 Reducing Overfitting with Weight Regularization\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import numpy as np \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create training and test sets\n",
    "features, target = make_classification(n_classes=2,\n",
    "                                       n_features=10,\n",
    "                                       n_samples=1000)\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "                            features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# convert data to pytorch tensors\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# Define a neural network using `Sequential`\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(10, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),   \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# Initialize neural network\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# define loss function , optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-4,\n",
    "                             weight_decay=1e-5)  # add weight regularization\n",
    "\n",
    "# define data loader\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# compile the model using torch optimizer\n",
    "network = torch.compile(network)\n",
    "\n",
    "# train neural network\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    for  batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# evaluate neuaral network\n",
    "with torch.no_grad():\n",
    "    output = network(x_test)\n",
    "    test_loss = criterion(output, y_test)\n",
    "    test_accuracy = (output.round() == y_test).float().mean()\n",
    "    print(\"Test LossL\", test_loss.item(), \"\\tTest Sccuracy:\", test_accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca55229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21.10 Reducing Overfitting with Early Stopping\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
